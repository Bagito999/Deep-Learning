{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/aYzJMyEuKTjMv/KdWG4W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bagito999/Deep-Learning/blob/main/Chapter_15_Teori.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Chapter 15 - Processing Sequences Using RNNs and CNNs\n",
        "\n",
        "##  Tujuan Bab\n",
        "\n",
        "Bab ini menjelaskan cara memproses data sekuensial seperti:\n",
        "- Teks (NLP)\n",
        "- Time series (data cuaca, harga saham)\n",
        "- Audio (suara, ucapan)\n",
        "\n",
        "Model yang dibahas:\n",
        "- Recurrent Neural Networks (RNN)\n",
        "- LSTM dan GRU\n",
        "- 1D Convolutional Neural Networks (CNN)\n",
        "\n",
        "---\n",
        "\n",
        "##  Data Sekuensial\n",
        "\n",
        "Karakteristik:\n",
        "- Urutan penting (tidak bisa diacak)\n",
        "- Panjang bisa bervariasi\n",
        "- Korelasi temporal antar elemen\n",
        "\n",
        "Contoh: “saya makan nasi” ≠ “nasi makan saya”\n",
        "\n",
        "---\n",
        "\n",
        "##  Recurrent Neural Networks (RNN)\n",
        "\n",
        "###  Arsitektur\n",
        "\n",
        "Setiap langkah waktu menggunakan:\n",
        "- Input saat ini \\($ x_t $\\)\n",
        "- State dari waktu sebelumnya \\($ h_{t-1} $\\)\n",
        "\n",
        "Output dan state dihitung:\n",
        "\n",
        "\\[\n",
        "$h_t = \\phi(W_{xh} x_t + W_{hh} h_{t-1} + b_h)$\n",
        "\\]\n",
        "\\[\n",
        "$y_t = W_{hy} h_t + b_y$\n",
        "\\]\n",
        "\n",
        "- \\($ \\phi $\\): fungsi aktivasi (biasanya tanh atau ReLU)\n",
        "\n",
        "---\n",
        "\n",
        "##  Masalah RNN Dasar\n",
        "\n",
        "1. **Vanishing Gradients**: gradien menghilang saat backpropagation jangka panjang\n",
        "2. **Exploding Gradients**: gradien membesar tak terkendali\n",
        "\n",
        "Solusi:\n",
        "- Truncated Backpropagation Through Time (TBPTT)\n",
        "- Arsitektur canggih seperti **LSTM** dan **GRU**\n",
        "\n",
        "---\n",
        "\n",
        "##  LSTM (Long Short-Term Memory)\n",
        "\n",
        "Memperkenalkan **cell state** \\($ C_t $\\) untuk membawa informasi jangka panjang.\n",
        "\n",
        "###  Komponen utama:\n",
        "\n",
        "- **Forget Gate**:\n",
        "\n",
        "\\[\n",
        "$f_t = \\sigma(W_f [h_{t-1}, x_t] + b_f)$\n",
        "\\]\n",
        "\n",
        "- **Input Gate**:\n",
        "\n",
        "\\[\n",
        "$i_t = \\sigma(W_i [h_{t-1}, x_t] + b_i)$\n",
        "\\]\n",
        "\\[\n",
        "$\\tilde{C}_t = \\tanh(W_C [h_{t-1}, x_t] + b_C)$\n",
        "\\]\n",
        "\n",
        "- **Cell State Update**:\n",
        "\n",
        "\\[\n",
        "$C_t = f_t \\cdot C_{t-1} + i_t \\cdot \\tilde{C}_t$\n",
        "\\]\n",
        "\n",
        "- **Output Gate**:\n",
        "\n",
        "\\[\n",
        "$o_t = \\sigma(W_o [h_{t-1}, x_t] + b_o)$\n",
        "\\]\n",
        "\\[\n",
        "$h_t = o_t \\cdot \\tanh(C_t)$\n",
        "\\]\n",
        "\n",
        "Kelebihan: dapat menyimpan dan membuang informasi sesuai konteks.\n",
        "\n",
        "---\n",
        "\n",
        "##  GRU (Gated Recurrent Unit)\n",
        "\n",
        "Simplifikasi dari LSTM:\n",
        "- Tidak memiliki cell state terpisah\n",
        "- Menggabungkan forget dan input gate\n",
        "\n",
        "###  Rumus GRU:\n",
        "\n",
        "- **Update Gate**:\n",
        "\n",
        "\\[\n",
        "$z_t = \\sigma(W_z [h_{t-1}, x_t])$\n",
        "\\]\n",
        "\n",
        "- **Reset Gate**:\n",
        "\n",
        "\\[\n",
        "$r_t = \\sigma(W_r [h_{t-1}, x_t])$\n",
        "\\]\n",
        "\n",
        "- **Candidate Activation**:\n",
        "\n",
        "\\[\n",
        "$\\tilde{h}_t = \\tanh(W_h [r_t \\cdot h_{t-1}, x_t])$\n",
        "\\]\n",
        "\n",
        "- **Final Output**:\n",
        "\n",
        "\\[\n",
        "$h_t = (1 - z_t) \\cdot h_{t-1} + z_t \\cdot \\tilde{h}_t$\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "##  Bidirectional RNN\n",
        "\n",
        "Melatih dua RNN:\n",
        "- Satu membaca maju (left to right)\n",
        "- Satu membaca mundur (right to left)\n",
        "\n",
        "Output digabungkan: \\($[h_t^{\\rightarrow}, h_t^{\\leftarrow}]$\\)\n",
        "\n",
        "Kelebihan:\n",
        "- Dapat melihat konteks dari dua arah\n",
        "\n",
        "---\n",
        "\n",
        "##  1D Convolutional Neural Networks\n",
        "\n",
        "Digunakan untuk data sekuensial dengan sifat lokal (misal: NLP)\n",
        "\n",
        "- Filter berjalan sepanjang urutan\n",
        "- Dapat menangkap fitur lokal seperti n-gram\n",
        "\n",
        "Kelebihan:\n",
        "- Cepat dilatih (komputasi paralel)\n",
        "- Stabil\n",
        "- Dapat dikombinasikan dengan RNN/LSTM\n",
        "\n",
        "---\n",
        "\n",
        "##  Pelatihan Model Sekuensial\n",
        "\n",
        "- Padding untuk menyamakan panjang input\n",
        "- Masking untuk mengabaikan padding\n",
        "- Gunakan loss function sequence-aware (misalnya CTC loss untuk speech)\n",
        "\n",
        "---\n",
        "\n",
        "##  Aplikasi CNN & RNN dalam NLP\n",
        "\n",
        "1. **Klasifikasi teks**: emosi, topik, spam\n",
        "2. **Pemodelan bahasa**: prediksi kata berikutnya\n",
        "3. **Machine translation**: input-output sekuens\n",
        "4. **Speech recognition**\n",
        "\n",
        "---\n",
        "\n",
        "##  Model Hybrid\n",
        "\n",
        "CNN + RNN:\n",
        "- CNN mengekstraksi fitur lokal\n",
        "- RNN menangani dependensi temporal global\n",
        "\n",
        "---\n",
        "\n",
        "##  Regularisasi dan Tuning\n",
        "\n",
        "- Dropout antara langkah waktu\n",
        "- Batch normalization (hati-hati untuk RNN)\n",
        "- Gradient clipping untuk menghindari exploding gradient\n",
        "\n",
        "---\n",
        "\n",
        "##  Kesimpulan\n",
        "\n",
        "- RNN efektif untuk memproses data sekuensial\n",
        "- LSTM dan GRU mengatasi masalah jangka panjang\n",
        "- CNN 1D cepat dan efektif untuk banyak tugas\n",
        "- Bidirectional dan hybrid model memperkuat konteks\n",
        "- Masking, padding, dan training khusus diperlukan\n",
        "\n",
        "---\n",
        "\n",
        "##  Referensi\n",
        "\n",
        "Géron, A. (2019). *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow*. O'Reilly Media.\n"
      ],
      "metadata": {
        "id": "6bgKvarKR9_m"
      }
    }
  ]
}