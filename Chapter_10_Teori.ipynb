{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMK6zV/53JHQpK1cl9/R4lC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bagito999/Deep-Learning/blob/main/Chapter_10_Teori.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Chapter 10 - Introduction to Artificial Neural Networks\n",
        "\n",
        "##  Pendahuluan\n",
        "\n",
        "Artificial Neural Networks (ANN) adalah fondasi dari Deep Learning. ANN terinspirasi oleh struktur dan fungsi otak manusia ‚Äî khususnya neuron biologis ‚Äî tetapi jauh lebih sederhana.\n",
        "\n",
        "ANN digunakan dalam:\n",
        "- Klasifikasi gambar\n",
        "- Pengenalan suara\n",
        "- Pemrosesan bahasa alami\n",
        "- Game dan kontrol robot\n",
        "\n",
        "---\n",
        "\n",
        "##  Struktur Dasar Neuron Buatan\n",
        "\n",
        "Neuron menerima input \\($ x_1, x_2, ..., x_n $\\), masing-masing dengan bobot \\($ w_1, w_2, ..., w_n $\\), dan menghasilkan output menggunakan fungsi aktivasi:\n",
        "\n",
        "### üîπ Perhitungan Neuron:\n",
        "\n",
        "\\[\n",
        "$z = \\sum_{i=1}^{n} w_i x_i + b = \\mathbf{w}^T \\mathbf{x} + b$\n",
        "\\]\n",
        "\n",
        "\\[\n",
        "$\\hat{y} = \\phi(z)$\n",
        "\\]\n",
        "\n",
        "- \\($ b $\\): bias\n",
        "- \\($ \\phi $\\): fungsi aktivasi (sigmoid, tanh, ReLU)\n",
        "\n",
        "---\n",
        "\n",
        "## üèóÔ∏è Arsitektur Jaringan Saraf\n",
        "\n",
        "ANN tersusun atas lapisan:\n",
        "- **Input Layer**\n",
        "- **Hidden Layers** (satu atau lebih)\n",
        "- **Output Layer**\n",
        "\n",
        "Setiap lapisan tersusun dari banyak neuron. ANN dengan banyak hidden layer disebut **Deep Neural Network (DNN)**.\n",
        "\n",
        "---\n",
        "\n",
        "## üîÑ Feedforward Neural Network\n",
        "\n",
        "Informasi mengalir dari input ‚Üí hidden layers ‚Üí output, tanpa loop. Disebut **feedforward** karena data hanya mengalir maju.\n",
        "\n",
        "---\n",
        "\n",
        "## üìà Fungsi Aktivasi Umum\n",
        "\n",
        "1. **Step Function**:\n",
        "   - Biner, tidak dapat dibedakan ‚Üí tidak digunakan dalam training modern.\n",
        "\n",
        "2. **Sigmoid**:\n",
        "\n",
        "\\[\n",
        "$\\sigma(z) = \\frac{1}{1 + e^{-z}}$\n",
        "\\]\n",
        "\n",
        "- Range: (0,1)\n",
        "- Masalah: vanishing gradient\n",
        "\n",
        "3. **Tanh**:\n",
        "\n",
        "\\[\n",
        "$\\tanh(z) = \\frac{e^z - e^{-z}}{e^z + e^{-z}}$\n",
        "\\]\n",
        "\n",
        "- Range: (-1,1)\n",
        "- Zero-centered\n",
        "\n",
        "4. **ReLU (Rectified Linear Unit)**:\n",
        "\n",
        "\\[\n",
        "$\\text{ReLU}(z) = \\max(0, z)$\n",
        "\\]\n",
        "\n",
        "- Cepat dan stabil\n",
        "- Rentan terhadap *dying ReLU*\n",
        "\n",
        "---\n",
        "\n",
        "##  Fungsi Loss\n",
        "\n",
        "### üî∏ Untuk Regresi:\n",
        "\n",
        "**Mean Squared Error (MSE):**\n",
        "\n",
        "\\[\n",
        "$\\text{MSE} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)})^2$\n",
        "\\]\n",
        "\n",
        "### üî∏ Untuk Klasifikasi:\n",
        "\n",
        "**Cross-Entropy Loss**:\n",
        "\n",
        "\\[\n",
        "$\\mathcal{L} = - \\sum_{i=1}^{m} \\sum_{k=1}^{K} y_k^{(i)} \\log(\\hat{y}_k^{(i)})$\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "##  Backpropagation\n",
        "\n",
        "Proses untuk melatih ANN menggunakan **gradient descent**. Langkah-langkah:\n",
        "\n",
        "1. **Forward pass**: hitung output untuk input saat ini.\n",
        "2. **Loss computation**: evaluasi fungsi loss.\n",
        "3. **Backward pass (Backpropagation)**:\n",
        "   - Hitung gradien loss terhadap setiap parameter.\n",
        "   - Gunakan **rantai aturan (chain rule)** untuk menyebarkan error dari output ke input.\n",
        "4. **Update weights**: dengan optimisasi (biasanya SGD):\n",
        "\n",
        "\\[\n",
        "$\\theta := \\theta - \\eta \\cdot \\nabla_\\theta \\mathcal{L}$\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "##  Contoh Pembelajaran\n",
        "\n",
        "- Dataset: MNIST (digit tulisan tangan)\n",
        "- Input: gambar 28x28 (784 fitur)\n",
        "- Hidden layers: beberapa lapisan ReLU\n",
        "- Output layer: Softmax (10 kelas)\n",
        "\n",
        "---\n",
        "\n",
        "##  Implementasi di Framework Modern\n",
        "\n",
        "- **TensorFlow**, **Keras**, dan **PyTorch** menyederhanakan pembangunan ANN\n",
        "- Layer seperti `Dense`, `Flatten`, dan `Activation` digunakan untuk membangun model\n",
        "\n",
        "---\n",
        "\n",
        "##  Kesimpulan\n",
        "\n",
        "- ANN adalah pondasi Deep Learning\n",
        "- Jaringan terdiri dari neuron buatan yang menggabungkan bobot dan fungsi aktivasi\n",
        "- Pelatihan dilakukan dengan **gradient descent** dan **backpropagation**\n",
        "- Fungsi aktivasi seperti ReLU dan loss seperti cross-entropy adalah kunci performa modern\n",
        "- Framework modern mempermudah pembangunan dan training ANN\n",
        "\n",
        "---\n",
        "\n",
        "##  Referensi\n",
        "\n",
        "G√©ron, A. (2019). *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow*. O'Reilly Media.\n"
      ],
      "metadata": {
        "id": "NLDCP0QLCH1C"
      }
    }
  ]
}