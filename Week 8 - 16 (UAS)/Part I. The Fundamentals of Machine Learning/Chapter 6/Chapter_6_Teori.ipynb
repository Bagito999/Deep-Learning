{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWvhARz3wFu9NlKeljOOZV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bagito999/Deep-Learning/blob/main/Chapter_6_Teori.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Chapter 6 - Decision Trees\n",
        "\n",
        "##  Apa Itu Decision Tree?\n",
        "\n",
        "Decision Tree adalah algoritma pembelajaran yang dapat digunakan untuk tugas klasifikasi maupun regresi. Mereka sangat intuitif, mudah divisualisasikan, dan tidak memerlukan scaling fitur.\n",
        "\n",
        "---\n",
        "\n",
        "##  Training dan Visualisasi Decision Tree\n",
        "\n",
        "Tree dilatih dengan memecah dataset menggunakan aturan keputusan biner berbasis pada fitur input. Proses ini berulang hingga kondisi tertentu terpenuhi (misal: kedalaman maksimal atau node menjadi pure).\n",
        "\n",
        "---\n",
        "\n",
        "##  Cara Prediksi\n",
        "\n",
        "Prediksi dilakukan dengan *menelusuri tree* dari akar ke daun:\n",
        "\n",
        "- Setiap node mengajukan pertanyaan (misalnya \"Apakah petal length â‰¤ 2.45?\").\n",
        "- Berdasarkan jawabannya (ya/tidak), pindah ke child node berikutnya.\n",
        "- Jika mencapai *leaf node*, ambil kelas mayoritas (atau nilai rata-rata untuk regresi).\n",
        "\n",
        "---\n",
        "\n",
        "##  Estimasi Probabilitas\n",
        "\n",
        "Untuk klasifikasi, tree juga bisa memberikan estimasi probabilitas dengan:\n",
        "\n",
        "\\[\n",
        "$P(k) = \\frac{\\text{Jumlah instance kelas } k}{\\text{Total instance di node}}$\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "##  Impurity Measures\n",
        "\n",
        "### ðŸ”¹ Gini Impurity\n",
        "\n",
        "\\[\n",
        "$G_i = 1 - \\sum_{k=1}^n p_{i,k}^2$\n",
        "\\]\n",
        "\n",
        "- Gini = 0: node pure\n",
        "- Digunakan default oleh Scikit-Learn\n",
        "\n",
        "### ðŸ”¸ Entropy\n",
        "\n",
        "\\[\n",
        "$H_i = - \\sum_{k=1}^{n} p_{i,k} \\log_2(p_{i,k})$\n",
        "\\]\n",
        "\n",
        "- Lebih lambat dari Gini\n",
        "- Mengarah ke tree lebih seimbang\n",
        "\n",
        "---\n",
        "\n",
        "##  CART Algorithm (Classification And Regression Tree)\n",
        "\n",
        "Digunakan oleh Scikit-Learn untuk membangun decision tree.\n",
        "\n",
        "### ðŸ”¹ Untuk Klasifikasi\n",
        "\n",
        "\\[\n",
        "$J(k, t_k) = \\frac{m_{left}}{m} G_{left} + \\frac{m_{right}}{m} G_{right}$\n",
        "\\]\n",
        "\n",
        "- Memilih fitur \\($k$\\) dan threshold \\($t_k$\\) yang meminimalkan impurity gabungan.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§® Kompleksitas Waktu\n",
        "\n",
        "- **Prediksi**: \\($O(\\log_2 m)$\\)\n",
        "- **Training**: \\($O(n \\cdot m \\cdot \\log_2 m)$\\)\n",
        "  - \\($n$\\): jumlah fitur\n",
        "  - \\($m$\\): jumlah instance\n",
        "\n",
        "---\n",
        "\n",
        "##  Regularisasi\n",
        "\n",
        "Untuk mencegah overfitting, beberapa parameter digunakan:\n",
        "\n",
        "- `max_depth`\n",
        "- `min_samples_split`\n",
        "- `min_samples_leaf`\n",
        "- `max_leaf_nodes`\n",
        "- `max_features`\n",
        "\n",
        "Model tanpa batasan cenderung overfit karena terlalu kompleks.\n",
        "\n",
        "---\n",
        "\n",
        "##  Pruning\n",
        "\n",
        "Alternatif dari regularisasi saat pelatihan adalah *post-pruning*:\n",
        "\n",
        "- Setelah pohon dibentuk, hapus node yang tidak memberi kontribusi signifikan.\n",
        "- Gunakan uji statistik seperti *chi-squared test*.\n",
        "\n",
        "---\n",
        "\n",
        "##  Decision Tree untuk Regresi\n",
        "\n",
        "- Sama seperti klasifikasi, tetapi leaf node memuat nilai rata-rata target.\n",
        "- **CART untuk regresi** meminimalkan **MSE**:\n",
        "\n",
        "\\[\n",
        "$J(k, t_k) = \\frac{m_{left}}{m} MSE_{left} + \\frac{m_{right}}{m} MSE_{right}$\n",
        "\\]\n",
        "\n",
        "Dengan:\n",
        "\n",
        "\\[\n",
        "$MSE = \\frac{1}{m_{node}} \\sum_{i \\in node} (y_i - \\bar{y})^2$\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "##  Kelemahan Decision Tree\n",
        "\n",
        "1. **Overfitting**: Terlalu sesuai dengan data training jika tidak diregularisasi.\n",
        "2. **Instabilitas**: Perubahan kecil di data â†’ perubahan besar di tree.\n",
        "3. **Sensitif terhadap rotasi fitur**: Karena split tegak lurus terhadap sumbu.\n",
        "4. **Model bersifat orthogonal**: Tidak efisien untuk batas keputusan miring.\n",
        "\n",
        "---\n",
        "\n",
        "##  White Box Model\n",
        "\n",
        "Decision Tree disebut *white box* karena keputusan mudah ditelusuri dan dijelaskan. Ini berbeda dari *black box model* seperti Neural Networks atau Random Forests.\n",
        "\n",
        "---\n",
        "\n",
        "##  Kesimpulan\n",
        "\n",
        "- Decision Tree sangat fleksibel, cocok untuk klasifikasi, regresi, dan multioutput.\n",
        "- Scikit-Learn menggunakan CART dan binary splits.\n",
        "- Gunakan regularisasi untuk mencegah overfitting.\n",
        "- Mereka intuitif dan mudah diinterpretasikan, tetapi sensitif terhadap data.\n",
        "\n",
        "---\n",
        "\n",
        "##  Referensi\n",
        "\n",
        "GÃ©ron, A. (2019). *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow*. O'Reilly Media.\n"
      ],
      "metadata": {
        "id": "9uHAyNHqe-py"
      }
    }
  ]
}
