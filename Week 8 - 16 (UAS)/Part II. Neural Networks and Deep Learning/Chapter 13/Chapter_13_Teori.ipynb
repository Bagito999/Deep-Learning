{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOv2bCuzJj1hP1OJYg3PC1g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bagito999/Deep-Learning/blob/main/Chapter_13_Teori.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Chapter 13 - Loading and Preprocessing Data with TensorFlow\n",
        "\n",
        "##  Tujuan Bab\n",
        "\n",
        "Bab ini membahas cara:\n",
        "- Memuat data efisien menggunakan `tf.data`\n",
        "- Melakukan preprocessing secara modular dan scalable\n",
        "- Mengoptimalkan input pipeline untuk performa maksimum\n",
        "\n",
        "---\n",
        "\n",
        "##  Tantangan dalam Input Data Pipeline\n",
        "\n",
        "1. Dataset besar tidak bisa dimuat sekaligus ke memori\n",
        "2. Perlu preprocessing yang cepat dan konsisten\n",
        "3. Training efisien membutuhkan pipeline input yang teroptimasi\n",
        "\n",
        "---\n",
        "\n",
        "##  API `tf.data`\n",
        "\n",
        "TensorFlow menyediakan API `tf.data` untuk:\n",
        "- Membuat objek `Dataset`\n",
        "- Melakukan transformasi data\n",
        "- Menangani pipeline streaming (lazy evaluation)\n",
        "\n",
        "### ðŸ”¹ Dataset Creation\n",
        "\n",
        "Beberapa cara umum:\n",
        "- Dari array: `from_tensor_slices()`\n",
        "- Dari file CSV/TFRecord: `TextLineDataset`, `TFRecordDataset`\n",
        "- Dari generator Python\n",
        "\n",
        "---\n",
        "\n",
        "##  Transformasi Dataset\n",
        "\n",
        "`Dataset` bersifat **lazy**, artinya operasi hanya dilakukan saat dibutuhkan.\n",
        "\n",
        "Transformasi umum:\n",
        "- `map()`: transformasi elemen\n",
        "- `filter()`: seleksi elemen\n",
        "- `batch()`: kelompokkan data\n",
        "- `shuffle()`: acak elemen\n",
        "- `repeat()`: ulangi dataset\n",
        "\n",
        "---\n",
        "\n",
        "##  Optimisasi Performance\n",
        "\n",
        "###  Prefetching\n",
        "\n",
        "`prefetch(n)` memungkinkan loading data dan training berjalan paralel.\n",
        "\n",
        "###  Interleaving & Parallel Mapping\n",
        "\n",
        "- `interleave()`: membaca beberapa file secara paralel\n",
        "- `map(..., num_parallel_calls=tf.data.AUTOTUNE)`: paralelisasi preprocessing\n",
        "\n",
        "###  Caching\n",
        "\n",
        "`cache()` menyimpan hasil transformasi agar tidak dihitung ulang setiap epoch.\n",
        "\n",
        "---\n",
        "\n",
        "##  Format Data: TFRecord\n",
        "\n",
        "Format biner efisien untuk data besar:\n",
        "- Kompresi tinggi\n",
        "- Dibaca dengan cepat\n",
        "- Digunakan luas di produksi (Google, TFX)\n",
        "\n",
        "Biasanya digunakan bersama dengan:\n",
        "- `TFRecordDataset`\n",
        "- `tf.train.Example` (untuk parsing protokol buffer)\n",
        "\n",
        "---\n",
        "\n",
        "##  TFRecord dan Protobuf\n",
        "\n",
        "### Struktur Record:\n",
        "```protobuf\n",
        "features {\n",
        "  feature {\n",
        "    key: \"feature_name\"\n",
        "    value: { float_list / int64_list / bytes_list }\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "##  Parsing dan Decoding\n",
        "\n",
        "Data perlu di-*decode* sesuai tipe dan struktur aslinya. Setelah data dibaca (misalnya dari file TFRecord), TensorFlow perlu mengetahui bagaimana menafsirkan byte tersebut.\n",
        "\n",
        "### Contoh decoding umum:\n",
        "\n",
        "- **Gambar**:\n",
        "  - JPEG â†’ `tf.io.decode_jpeg()`\n",
        "  - PNG â†’ `tf.io.decode_png()`\n",
        "- **Teks/Bytes**:\n",
        "  - â†’ `tf.io.decode_raw()`\n",
        "- **Label numerik**:\n",
        "  - â†’ `tf.cast()` ke `tf.int64` atau `tf.float32`\n",
        "- **Parsing TFRecord**:\n",
        "  - Gunakan `tf.io.parse_single_example(serialized_example, feature_description)`\n",
        "\n",
        "### ðŸ”¹ Feature Description\n",
        "\n",
        "Untuk mem-parsing TFRecord, deskripsi fitur dibutuhkan:\n",
        "```python\n",
        "feature_description = {\n",
        "  'image': tf.io.FixedLenFeature([], tf.string),\n",
        "  'label': tf.io.FixedLenFeature([], tf.int64)\n",
        "}\n",
        "```\n",
        "\n",
        "##  Preprocessing Data\n",
        "\n",
        "Transformasi umum yang dilakukan sebelum data masuk ke model:\n",
        "\n",
        "- **Normalisasi**: skala nilai ke rentang stabil (misalnya 0â€“1)\n",
        "- **Standarisasi**: kurangi nilai rata-rata, bagi dengan standar deviasi\n",
        "- **Resizing**: menyesuaikan ukuran input (misalnya gambar ke 224x224)\n",
        "- **Augmentasi Data**: rotasi, flipping, cropping, zoom untuk meningkatkan generalisasi\n",
        "- **Tokenisasi**: memecah teks menjadi kata/karakter dan mengubahnya ke indeks\n",
        "- **Padding**: menyesuaikan panjang teks agar seragam untuk batch processing\n",
        "\n",
        "###  Pilihan Lokasi Preprocessing:\n",
        "\n",
        "1. **Offline Preprocessing**  \n",
        "   - Lakukan sebelum training dan simpan ke disk (file .npy, TFRecord, dll)\n",
        "\n",
        "2. **In-pipeline Preprocessing (tf.data)**  \n",
        "   - Gunakan fungsi `map()` dalam pipeline data\n",
        "\n",
        "3. **In-model Preprocessing**  \n",
        "   - Gunakan layer seperti `tf.keras.layers.Rescaling`, `Resizing`, `TextVectorization`\n",
        "\n",
        "---\n",
        "\n",
        "##  Bandingkan: Preprocessing di Model vs Dataset\n",
        "\n",
        "| Lokasi Preprocessing   | Keunggulan                         | Kelemahan                            |\n",
        "|------------------------|------------------------------------|--------------------------------------|\n",
        "| **Di dalam model**     | Portable, dapat di-deploy bersama model | Lebih lambat saat inferensi            |\n",
        "| **Dalam tf.data pipeline** | Cepat dan fleksibel selama training    | Tidak otomatis dibawa saat ekspor model |\n",
        "| **Offline preprocessing** | Konsisten, bisa didistribusi       | Tidak fleksibel terhadap perubahan    |\n",
        "\n",
        "---\n",
        "\n",
        "##  Mengatur Pipeline untuk Performance Maksimal\n",
        "\n",
        "Agar training efisien, ikuti urutan transformasi berikut:\n",
        "\n",
        "```text\n",
        "Load â†’ Shuffle â†’ Cache â†’ Batch â†’ Prefetch\n",
        "```\n",
        "\n",
        "##  TFX: TensorFlow Extended\n",
        "\n",
        "**TFX (TensorFlow Extended)** adalah platform end-to-end produksi machine learning yang dirancang untuk membangun dan mengelola pipeline ML berbasis TensorFlow dalam skala besar.\n",
        "\n",
        "TFX digunakan untuk:\n",
        "- Persiapan data\n",
        "- Pelatihan model\n",
        "- Evaluasi model\n",
        "- Deployment model ke produksi\n",
        "\n",
        "###  Komponen Utama TFX:\n",
        "\n",
        "- **ExampleGen**  \n",
        "  Komponen pertama yang mengimpor data dari berbagai sumber dan mengubahnya menjadi format standar TFRecord.\n",
        "\n",
        "- **StatisticsGen**  \n",
        "  Menghitung statistik data seperti distribusi, mean, standar deviasi, missing values, dll.\n",
        "\n",
        "- **SchemaGen**  \n",
        "  Menganalisis statistik dan menghasilkan skema fitur yang menjelaskan jenis dan batasan data.\n",
        "\n",
        "- **ExampleValidator**  \n",
        "  Mendeteksi anomali, missing values, dan outlier berdasarkan skema.\n",
        "\n",
        "- **Transform**  \n",
        "  Menerapkan preprocessing skala besar dengan TensorFlow Transform (TFT), sehingga preprocessing dapat digunakan saat training dan inferensi.\n",
        "\n",
        "- **Trainer**  \n",
        "  Melatih model TensorFlow menggunakan arsitektur Keras atau Estimator.\n",
        "\n",
        "- **Tuner (opsional)**  \n",
        "  Untuk hyperparameter tuning otomatis.\n",
        "\n",
        "- **Evaluator**  \n",
        "  Mengevaluasi model untuk memilih versi terbaik berdasarkan metrik (accuracy, fairness, dll).\n",
        "\n",
        "- **InfraValidator**  \n",
        "  Memastikan model dapat di-*serve* sebelum benar-benar dikirim ke produksi.\n",
        "\n",
        "- **Pusher**  \n",
        "  Menyimpan model akhir dan mengirimnya ke sistem serving seperti TensorFlow Serving.\n",
        "\n",
        "---\n",
        "\n",
        "##  Rumus dan Konsep Kunci\n",
        "\n",
        "###  Normalisasi\n",
        "\n",
        "Menstabilkan dan menskalakan input:\n",
        "\n",
        "\\[\n",
        "$x_{\\text{norm}} = \\frac{x - \\mu}{\\sigma}$\n",
        "\\]\n",
        "\n",
        "- \\($ x $\\): nilai asli\n",
        "- \\($ \\mu $\\): rata-rata\n",
        "- \\($ \\sigma $\\): deviasi standar\n",
        "\n",
        "Digunakan untuk mencegah dominasi fitur dengan skala besar terhadap model.\n",
        "\n",
        "---\n",
        "\n",
        "###  Shuffle Buffer Size\n",
        "\n",
        "Buffer digunakan saat proses `shuffle()` untuk mengacak data sebelum batching.\n",
        "\n",
        "- **Buffer besar** â†’ pengacakan lebih acak, tetapi butuh memori lebih besar.\n",
        "- Ideal: `buffer_size >= dataset size` jika memori memungkinkan.\n",
        "\n",
        "---\n",
        "\n",
        "###  Pipeline Optimisasi\n",
        "\n",
        "**Urutan pipeline optimal**:\n",
        "\n",
        "```text\n",
        "Load â†’ Shuffle â†’ Cache â†’ Batch â†’ Prefetch\n",
        "```\n",
        "\n",
        "###  Pipeline dengan tf.data â€” Optimasi Performa\n",
        "\n",
        "Gunakan kombinasi transformasi berikut untuk membuat pipeline data yang efisien:\n",
        "\n",
        "- `shuffle(buffer_size)`  \n",
        "  Mengacak urutan data agar training tidak terpengaruh pola data statis.  \n",
        "  Buffer size menentukan seberapa acak pengocokan data dan berapa banyak memori yang digunakan.\n",
        "\n",
        "- `cache()`  \n",
        "  Menyimpan hasil transformasi dataset di memori atau disk setelah pertama kali diproses.  \n",
        "  Hal ini menghindari pengulangan preprocessing setiap epoch, sehingga training menjadi lebih cepat.\n",
        "\n",
        "- `batch(batch_size)`  \n",
        "  Mengelompokkan data menjadi batch agar dapat diproses secara paralel selama training.  \n",
        "  Batch size yang lebih besar meningkatkan efisiensi GPU, namun perlu disesuaikan dengan kapasitas memori.\n",
        "\n",
        "- `prefetch(tf.data.AUTOTUNE)`  \n",
        "  Melakukan *overlapping* antara loading data di CPU dan training di GPU.  \n",
        "  `AUTOTUNE` secara otomatis memilih jumlah buffer yang optimal.\n",
        "\n",
        "###  Urutan Pipeline Ideal\n",
        "\n",
        "```python\n",
        "dataset.shuffle(buffer_size)\n",
        "       .cache()\n",
        "       .batch(batch_size)\n",
        "       .prefetch(tf.data.AUTOTUNE)\n",
        "```\n",
        "\n",
        "##  Kesimpulan\n",
        "\n",
        "- **`tf.data` API** menyediakan cara yang efisien, modular, dan scalable untuk membangun pipeline data di TensorFlow, cocok untuk dataset kecil hingga sangat besar.\n",
        "\n",
        "- Gunakan transformasi penting dalam pipeline seperti:\n",
        "  - `shuffle()` untuk mencegah overfitting urutan data\n",
        "  - `cache()` untuk menghindari komputasi berulang\n",
        "  - `batch()` untuk pelatihan paralel\n",
        "  - `prefetch()` untuk overlapping CPU dan GPU\n",
        "\n",
        "- **TFRecord** adalah format penyimpanan data yang efisien dan cocok untuk produksi, terutama untuk training skala besar dan distribusi.\n",
        "\n",
        "- **Preprocessing** dapat dilakukan:\n",
        "  - **Offline**: efisien untuk data statis\n",
        "  - **Dalam pipeline `tf.data`**: fleksibel dan cocok untuk eksperimen\n",
        "  - **Di dalam model**: portable dan otomatis dibawa saat deploy\n",
        "\n",
        "- Gunakan **TFX (TensorFlow Extended)** untuk pipeline ML produksi end-to-end:\n",
        "  - Menyediakan komponen untuk ingest data, preprocessing, training, evaluasi, dan deployment.\n",
        "\n",
        "- Pipeline yang dioptimalkan akan:\n",
        "  - Mengurangi waktu epoch secara drastis\n",
        "  - Mengurangi penggunaan CPU/GPU yang tidak efisien\n",
        "  - Memastikan proses pelatihan stabil, konsisten, dan scalable\n",
        "\n",
        "## Referensi\n",
        "GÃ©ron, A. (2019). *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow*. O'Reilly Media."
      ],
      "metadata": {
        "id": "ZW9UzngCKvoO"
      }
    }
  ]
}
